{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import threading\n"
      ],
      "metadata": {
        "id": "OV3FwxsZ-geu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected Singleton Metaclass\n",
        "class Singleton(type):\n",
        "    _instances = {}\n",
        "    def __call__(cls, *args, **kwargs):\n",
        "        if cls not in cls._instances:\n",
        "            cls._instances[cls] = super().__call__(*args, **kwargs)  # Corrected super() call\n",
        "        return cls._instances[cls]\n",
        "\n",
        "# Model Loader Factory (same as before)\n",
        "class ModelLoaderFactory:\n",
        "    loaders = {\n",
        "\n",
        "               \"keras\" : lambda path: tf.keras.models.load_model(path),\n",
        "               \"h5\": lambda path: tf.keras.models.load_model(path),\n",
        "               \"pb\": lambda path: tf.saved_model.load(path),\n",
        "               \"pt\": lambda path: torch.jit.load(path)}\n",
        "\n",
        "    @staticmethod\n",
        "    def get_loader(extension):\n",
        "        loader = ModelLoaderFactory.loaders.get(extension.lower())\n",
        "        if loader is None:\n",
        "            raise ValueError(f\"Unsupported model format: {extension}\")\n",
        "        return loader\n",
        "\n"
      ],
      "metadata": {
        "id": "1cC64gFl6mvH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Strategies (Singleton) (same as before)\n",
        "class PreprocessingStrategy(metaclass=Singleton):\n",
        "    def apply(self, image):\n",
        "        raise NotImplementedError(\"Subclasses must implement apply method.\")\n",
        "\n",
        "class CataractPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        return cv2.convertScaleAbs(image, alpha=1.0, beta=50)\n",
        "\n",
        "class DiabetesPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        green_channel = image[:, :, 1]\n",
        "        red_free_image = cv2.merge([green_channel, green_channel, green_channel])\n",
        "        return cv2.convertScaleAbs(red_free_image, alpha=1.5, beta=50)\n",
        "\n",
        "class GlaucomaPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = image / 255.0\n",
        "        return image.astype(np.float32)\n",
        "\n",
        "class HypertensionPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        green_channel = image[:, :, 1]\n",
        "        red_free_image = cv2.equalizeHist(green_channel)\n",
        "        edges = cv2.Canny(red_free_image, 50, 150)\n",
        "        blurred = cv2.GaussianBlur(red_free_image, (5, 5), 0)\n",
        "        return np.stack([red_free_image, edges, blurred], axis=-1)\n",
        "\n",
        "class PathologicalMyopiaPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        return cv2.resize(image, (224, 224))\n",
        "\n",
        "class AgeIssuesPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "        enhanced_image = clahe.apply(gray_image)\n",
        "        image_faf = cv2.cvtColor(enhanced_image, cv2.COLOR_GRAY2BGR)\n",
        "        edges = cv2.Canny(image, 100, 200)\n",
        "        return cv2.addWeighted(image, 0.8, cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 0.2, 0)\n"
      ],
      "metadata": {
        "id": "QAyIkvPT6uP-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eyes Model (same as before)\n",
        "class EyesModel:\n",
        "    _model_cache = {}\n",
        "    _cache_lock = threading.Lock()\n",
        "\n",
        "\n",
        "    def __init__(self, model_path, strategy):\n",
        "        self.model_path = model_path\n",
        "        self.strategy = strategy\n",
        "        self.model = self._load_model()\n",
        "\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        # Two models are considered equal if they share the same path and strategy\n",
        "        return isinstance(other, EyesModel) and \\\n",
        "               self.model_path == other.model_path and \\\n",
        "               type(self.strategy) == type(other.strategy)\n",
        "\n",
        "    def __hash__(self):\n",
        "        # Hash based on model path and strategy type\n",
        "        return hash((self.model_path, type(self.strategy)))\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"EyesModel(model_path={self.model_path}, strategy={type(self.strategy)})\"\n",
        "\n",
        "    def _load_model(self):\n",
        "        with EyesModel._cache_lock:\n",
        "            if self.model_path not in EyesModel._model_cache:\n",
        "                extension = self.model_path.split('.')[-1]\n",
        "                loader = ModelLoaderFactory.get_loader(extension)\n",
        "                if loader:\n",
        "                    EyesModel._model_cache[self.model_path] = loader(self.model_path)\n",
        "            return EyesModel._model_cache[self.model_path]\n",
        "\n",
        "    def diagnose(self, left_image, right_image):\n",
        "        left_processed = self.strategy.apply(left_image)\n",
        "        right_processed = self.strategy.apply(right_image)\n",
        "        left_result = self.model.predict(np.expand_dims(left_processed, axis=0))[0]\n",
        "        right_result = self.model.predict(np.expand_dims(right_processed, axis=0))[0]\n",
        "        return left_result, right_result\n"
      ],
      "metadata": {
        "id": "Ojo9L35wnXyf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    def diagnose(self, left_image, right_image):\n",
        "        left_processed = self.strategy.apply(left_image)\n",
        "        right_processed = self.strategy.apply(right_image)\n",
        "        left_result = self.model.predict(np.expand_dims(left_processed, axis=0))[0]\n",
        "        right_result = self.model.predict(np.expand_dims(right_processed, axis=0))[0]\n",
        "        return left_result, right_result\n",
        "for eyes_model\n",
        "\"\"\"\"\n",
        "\n",
        "\"\"\"\"\n",
        "# Diagnoser (Singleton) (same as before)\n",
        "class Diagnoser(metaclass=Singleton):\n",
        "    def __init__(self):\n",
        "        #self.models = []\n",
        "        self.models = set()  # Use a set to store models and ensure uniqueness\n",
        "\n",
        "    def add_model(self, model):\n",
        "        # Models will be automatically deduplicated based on __hash__ and __eq__\n",
        "        self.models.add(model)\n",
        "        #self.models.append(model)\n",
        "\n",
        "    def predict(self, left_image, right_image):\n",
        "        # Serial execution to ensure order is maintained\n",
        "        results = [model.diagnose(left_image, right_image) for model in self.models]\n",
        "        return results\n",
        "\n",
        "        \"\"\""
      ],
      "metadata": {
        "id": "mHi5duYm7RTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "class Diagnoser:\n",
        "    def __init__(self):\n",
        "        # Use a list to store models and ensure uniqueness\n",
        "        self.models = []\n",
        "\n",
        "    def add_model(self, model):\n",
        "        \"\"\"\n",
        "        Add a model to the Diagnoser, ensuring uniqueness based on __hash__ and __eq__.\n",
        "        \"\"\"\n",
        "        if model not in self.models:\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict(self, left_image, right_image, parallel=False):\n",
        "        \"\"\"\n",
        "        Generate predictions using all models.\n",
        "\n",
        "        Args:\n",
        "        - left_image: Image for the left eye.\n",
        "        - right_image: Image for the right eye.\n",
        "        - parallel (bool): Whether to execute predictions in parallel.\n",
        "\n",
        "        Returns:\n",
        "        - results (list): Predictions from all models in the correct order.\n",
        "        \"\"\"\n",
        "        if parallel:\n",
        "            # Map each model to its index to maintain order\n",
        "            model_to_index = {model: idx for idx, model in enumerate(self.models)}\n",
        "\n",
        "            # Function to process a model and preserve index\n",
        "            def process_model(model):\n",
        "                return model_to_index[model], model.diagnose(left_image, right_image)\n",
        "\n",
        "            # Initialize a list to store results in the correct order\n",
        "            results = [None] * len(self.models)\n",
        "\n",
        "            # Execute predictions in parallel with ThreadPoolExecutor\n",
        "            with ThreadPoolExecutor() as executor:\n",
        "                for index, result in executor.map(process_model, self.models):\n",
        "                    results[index] = result  # Store results at respective indices\n",
        "\n",
        "        else:\n",
        "            # Serial execution ensures order naturally\n",
        "            results = [model.diagnose(left_image, right_image) for model in self.models]\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "8u_MCEZk7Ux4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "      \"\"\"\n",
        "    def predict(self, left_image, right_image):\n",
        "        #from concurrent.futures import ThreadPoolExecutor\n",
        "        #with ThreadPoolExecutor() as executor:\n",
        "        results = list(executor.map(lambda model: model.diagnose(left_image, right_image), self.models))\n",
        "        return results\n",
        "      \"\"\"\n"
      ],
      "metadata": {
        "id": "nAK3kpgz-ff9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    def load_example_image(path):\n",
        "        return np.random.rand(224, 224, 3).astype(np.uint8)\n",
        "\n",
        "    left_image_data = load_example_image(\"left_eye.jpg\")\n",
        "    right_image_data = load_example_image(\"right_eye.jpg\")\n",
        "\n",
        "    diagnoser = Diagnoser()\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/cataract_model_wiht_filter.keras\", CataractPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/diabetic_model_wiht_filter.keras\", DiabetesPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/glaucoma_model_wiht_filter.keras\", GlaucomaPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/hyper_model_wiht_filter.keras\", HypertensionPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/Myopia_model_2.h5\", PathologicalMyopiaPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/age_model_wiht_filter.keras\", AgeIssuesPreprocessing()))\n",
        "\n",
        "    predictions = diagnoser.predict(left_image_data, right_image_data)\n",
        "    print(\"Predictions:\", predictions)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FfkDtAI57Kt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming Diagnoser, EyesModel, and Preprocessing strategies are defined as in the previous response\n",
        "\n",
        "# Step 1: Loading the dataset and organizing image paths\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"magdhndi\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"9b6c8953fb75d807a407f863ae22edc6\"\n",
        "\n",
        "!kaggle datasets download andrewmvd/ocular-disease-recognition-odir5k\n",
        "!unzip ocular-disease-recognition-odir5k\n"
      ],
      "metadata": {
        "id": "GtdP73bS7ZPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/full_df.csv\")\n",
        "\n",
        "cach_df = df\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "GokkcSp87gJW",
        "outputId": "92ac83df-173d-4753-cd4e-f852f4cf0696"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
              "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
              "1   1           57        Male  1_left.jpg  1_right.jpg   \n",
              "2   2           42        Male  2_left.jpg  2_right.jpg   \n",
              "3   4           53        Male  4_left.jpg  4_right.jpg   \n",
              "4   5           50      Female  5_left.jpg  5_right.jpg   \n",
              "\n",
              "                            Left-Diagnostic Keywords  \\\n",
              "0                                           cataract   \n",
              "1                                      normal fundus   \n",
              "2  laser spot，moderate non proliferative retinopathy   \n",
              "3                        macular epiretinal membrane   \n",
              "4             moderate non proliferative retinopathy   \n",
              "\n",
              "                Right-Diagnostic Keywords  N  D  G  C  A  H  M  O  \\\n",
              "0                           normal fundus  0  0  0  1  0  0  0  0   \n",
              "1                           normal fundus  1  0  0  0  0  0  0  0   \n",
              "2  moderate non proliferative retinopathy  0  1  0  0  0  0  0  1   \n",
              "3       mild nonproliferative retinopathy  0  1  0  0  0  0  0  1   \n",
              "4  moderate non proliferative retinopathy  0  1  0  0  0  0  0  0   \n",
              "\n",
              "                                            filepath labels  \\\n",
              "0  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
              "1  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
              "2  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
              "3  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
              "4  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
              "\n",
              "                     target     filename  \n",
              "0  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg  \n",
              "1  [1, 0, 0, 0, 0, 0, 0, 0]  1_right.jpg  \n",
              "2  [0, 1, 0, 0, 0, 0, 0, 0]  2_right.jpg  \n",
              "3  [0, 1, 0, 0, 0, 0, 0, 0]  4_right.jpg  \n",
              "4  [0, 1, 0, 0, 0, 0, 0, 0]  5_right.jpg  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d52d3849-6a2c-4a3c-939d-338d0b406684\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Sex</th>\n",
              "      <th>Left-Fundus</th>\n",
              "      <th>Right-Fundus</th>\n",
              "      <th>Left-Diagnostic Keywords</th>\n",
              "      <th>Right-Diagnostic Keywords</th>\n",
              "      <th>N</th>\n",
              "      <th>D</th>\n",
              "      <th>G</th>\n",
              "      <th>C</th>\n",
              "      <th>A</th>\n",
              "      <th>H</th>\n",
              "      <th>M</th>\n",
              "      <th>O</th>\n",
              "      <th>filepath</th>\n",
              "      <th>labels</th>\n",
              "      <th>target</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>Female</td>\n",
              "      <td>0_left.jpg</td>\n",
              "      <td>0_right.jpg</td>\n",
              "      <td>cataract</td>\n",
              "      <td>normal fundus</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['N']</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>0_right.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>Male</td>\n",
              "      <td>1_left.jpg</td>\n",
              "      <td>1_right.jpg</td>\n",
              "      <td>normal fundus</td>\n",
              "      <td>normal fundus</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['N']</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>1_right.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>Male</td>\n",
              "      <td>2_left.jpg</td>\n",
              "      <td>2_right.jpg</td>\n",
              "      <td>laser spot，moderate non proliferative retinopathy</td>\n",
              "      <td>moderate non proliferative retinopathy</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['D']</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>2_right.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>Male</td>\n",
              "      <td>4_left.jpg</td>\n",
              "      <td>4_right.jpg</td>\n",
              "      <td>macular epiretinal membrane</td>\n",
              "      <td>mild nonproliferative retinopathy</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['D']</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>4_right.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>Female</td>\n",
              "      <td>5_left.jpg</td>\n",
              "      <td>5_right.jpg</td>\n",
              "      <td>moderate non proliferative retinopathy</td>\n",
              "      <td>moderate non proliferative retinopathy</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['D']</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>5_right.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d52d3849-6a2c-4a3c-939d-338d0b406684')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d52d3849-6a2c-4a3c-939d-338d0b406684 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d52d3849-6a2c-4a3c-939d-338d0b406684');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-062b00f7-33c3-4b33-9d96-77d1ce8a8873\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-062b00f7-33c3-4b33-9d96-77d1ce8a8873')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-062b00f7-33c3-4b33-9d96-77d1ce8a8873 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6392,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1417,\n        \"min\": 0,\n        \"max\": 4784,\n        \"num_unique_values\": 3358,\n        \"samples\": [\n          1419,\n          2470,\n          1975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 1,\n        \"max\": 91,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          50,\n          24,\n          58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Left-Fundus\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3358,\n        \"samples\": [\n          \"1419_left.jpg\",\n          \"2470_left.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Right-Fundus\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3358,\n        \"samples\": [\n          \"1419_right.jpg\",\n          \"2470_right.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Left-Diagnostic Keywords\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 196,\n        \"samples\": [\n          \"glaucoma\\uff0cmyopia retinopathy\",\n          \"suspected glaucoma\\uff0csuspicious diabetic retinopathy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Right-Diagnostic Keywords\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 205,\n        \"samples\": [\n          \"dry age-related macular degeneration\\uff0cglaucoma\",\n          \"drusen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"G\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"O\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filepath\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6392,\n        \"samples\": [\n          \"../input/ocular-disease-recognition-odir5k/ODIR-5K/Training Images/3969_right.jpg\",\n          \"../input/ocular-disease-recognition-odir5k/ODIR-5K/Training Images/2391_left.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"['D']\",\n          \"['C']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"[0, 1, 0, 0, 0, 0, 0, 0]\",\n          \"[0, 0, 0, 1, 0, 0, 0, 0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6392,\n        \"samples\": [\n          \"3969_right.jpg\",\n          \"2391_left.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bECe8LTmfO_x",
        "outputId": "1f5d483d-eaab-4dff-a540-413ce81c3653"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.head(1)\n",
        "dataset_dir = \"/content/ODIR-5K/ODIR-5K/Training Images\"\n",
        "image_size = 224\n",
        "\n",
        "diagnoser = Diagnoser()\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/cataract_model_wiht_filter.keras\", CataractPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/diabetic_model_wiht_filter.keras\", DiabetesPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/glaucoma_model_wiht_filter.keras\", GlaucomaPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/hyper_model_wiht_filter.keras\", HypertensionPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/Myopia_model_2.h5\", PathologicalMyopiaPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/age_model_wiht_filter.keras\", AgeIssuesPreprocessing()))\n"
      ],
      "metadata": {
        "id": "e6U5-Xt7fJW-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in diagnoser.models:\n",
        "    print(type(model.strategy))  # Prints the class of each strategy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr7snNiRrfyt",
        "outputId": "09c6fecf-e47b-4052-d42b-494d5327651c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.CataractPreprocessing'>\n",
            "<class '__main__.DiabetesPreprocessing'>\n",
            "<class '__main__.GlaucomaPreprocessing'>\n",
            "<class '__main__.HypertensionPreprocessing'>\n",
            "<class '__main__.PathologicalMyopiaPreprocessing'>\n",
            "<class '__main__.AgeIssuesPreprocessing'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_predict(left_image_path, right_image_path):\n",
        "    \"\"\"Loads, preprocesses, and predicts using Diagnoser for a pair of images.\"\"\"\n",
        "    try:\n",
        "        left_image = cv2.imread(left_image_path, cv2.IMREAD_COLOR)\n",
        "        right_image = cv2.imread(right_image_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if left_image is None or right_image is None:\n",
        "            print(f\"Warning: Could not read one or both images.\")\n",
        "            return None\n",
        "\n",
        "        left_image = cv2.resize(left_image, (image_size, image_size))\n",
        "        right_image = cv2.resize(right_image, (image_size, image_size))\n",
        "\n",
        "        prediction = diagnoser.predict(left_image, right_image, parallel=True)  # Parallel execution with guaranteed order\n",
        "        return prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing images: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "_wAKkyZEghpX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def process_in_batches(df, start_row, batch_size, dataset_dir, output_file=\"predictions.csv\"):\n",
        "    \"\"\"\n",
        "    Processes rows in the DataFrame in batches and saves predictions to a CSV file.\n",
        "\n",
        "    Args:\n",
        "    - df (pd.DataFrame): Input DataFrame with records to process.\n",
        "    - start_row (int): Starting row index.\n",
        "    - batch_size (int): Number of rows to process in each batch.\n",
        "    - dataset_dir (str): Directory containing the images.\n",
        "    - output_file (str): Path to the output CSV file.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # Ensure start_row and batch_size are valid\n",
        "    assert start_row >= 0, \"Start row must be non-negative\"\n",
        "    assert batch_size > 0, \"Batch size must be a positive integer\"\n",
        "\n",
        "    # Slice the DataFrame for the given batch\n",
        "    end_row = min(start_row + batch_size, len(df))\n",
        "    batch_df = df.iloc[start_row:end_row]\n",
        "\n",
        "    # Initialize results list\n",
        "    results = []\n",
        "\n",
        "    # Process each row in the batch\n",
        "    for index, row in tqdm(batch_df.iterrows(), total=batch_df.shape[0], desc=f\"Processing rows {start_row} to {end_row}\"):\n",
        "        age = row['Patient Age']\n",
        "        sex = row['Patient Sex']\n",
        "        left_fundus = os.path.join(dataset_dir, row['Left-Fundus'])\n",
        "        right_fundus = os.path.join(dataset_dir, row['Right-Fundus'])\n",
        "        correct_diagnosis = [row['N'], row['D'], row['G'], row['C'], row['A'], row['H'], row['M']]\n",
        "\n",
        "        # Perform prediction\n",
        "        prediction = load_and_predict(left_fundus, right_fundus)\n",
        "\n",
        "        if prediction:\n",
        "            cataract_prob, diabetic_prob, glaucoma_prob, hyper_prob, myopia_prob, age_prob = prediction\n",
        "\n",
        "            # Left and right eye results\n",
        "            left_sorted = [cataract_prob[0][0], diabetic_prob[0][0], glaucoma_prob[0][0],\n",
        "                           hyper_prob[0][0], myopia_prob[0][0], age_prob[0][0]]\n",
        "            right_sorted = [cataract_prob[1][0], diabetic_prob[1][0], glaucoma_prob[1][0],\n",
        "                            hyper_prob[1][0], myopia_prob[1][0], age_prob[1][0]]\n",
        "\n",
        "            # Append results\n",
        "            results.append([age, sex] + left_sorted + right_sorted + correct_diagnosis)\n",
        "\n",
        "\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "0wFhx68q8InO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "# Assuming `df` is already defined and loaded\n",
        "results = process_in_batches(cach_df, start_row=0, batch_size=5, dataset_dir=\"/content/ODIR-5K/ODIR-5K/Training Images\", output_file=\"predictions.csv\")\n"
      ],
      "metadata": {
        "id": "1XtR4FJHJtaN",
        "outputId": "388140e2-0787-4119-a455-e1d13ace3b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:  20%|██        | 1/5 [00:07<00:29,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:  40%|████      | 2/5 [00:13<00:20,  6.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:  60%|██████    | 3/5 [00:22<00:15,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:  80%|████████  | 4/5 [00:28<00:07,  7.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing rows 0 to 5: 100%|██████████| 5/5 [00:38<00:00,  7.66s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file=\"predictions.csv\"\n",
        "start_row=0\n",
        "end_row = 5\n",
        "# Assertions for the batch results\n",
        "#assert len(results) == len(batch_df), f\"Results length mismatch: expected {len(batch_df)}, got {len(results)}\"\n",
        "\n",
        "# Define column names\n",
        "columns = ['Age', 'Sex', 'Left_cataract', 'Left_diabetic', 'Left_glaucoma', 'Left_hyper', 'Left_Myopia', 'Left_age',\n",
        "            'Right_cataract', 'Right_diabetic', 'Right_glaucoma', 'Right_hyper', 'Right_Myopia', 'Right_age',\n",
        "            'N', 'D', 'G', 'C', 'A', 'H', 'M']\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results, columns=columns)\n",
        "\n",
        "# Display a preview of the results\n",
        "print(results_df.head())\n",
        "\n",
        "# Save results to a CSV file\n",
        "if os.path.exists(output_file):\n",
        "    # Append without overwriting the file\n",
        "    results_df.to_csv(output_file, mode='a', header=False, index=False)\n",
        "else:\n",
        "    # Create a new file\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Batch from {start_row} to {end_row} processed and saved to {output_file}\")\n"
      ],
      "metadata": {
        "id": "OmhvfxV7JoJj",
        "outputId": "6ac4114b-3851-4764-9edd-d9c694c66597",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Age     Sex  Left_cataract  Left_diabetic  Left_glaucoma    Left_hyper  \\\n",
            "0   69  Female   1.000000e+00   2.546632e-06       0.175294  6.784076e-10   \n",
            "1   57    Male   3.026999e-09   1.389067e-01       0.221712  1.051806e-07   \n",
            "2   42    Male   9.973556e-01   9.979500e-01       0.198193  6.392049e-11   \n",
            "3   53    Male   8.908896e-01   2.037923e-07       0.343581  2.397901e-11   \n",
            "4   50  Female   6.744714e-17   2.790738e-05       0.192183  2.162522e-10   \n",
            "\n",
            "    Left_Myopia      Left_age  Right_cataract  Right_diabetic  ...  \\\n",
            "0  4.678401e-17  3.261969e-02    6.574120e-02        0.000059  ...   \n",
            "1  3.471462e-22  3.751020e-03    4.485955e-12        0.003587  ...   \n",
            "2  1.102241e-08  9.995713e-01    1.676708e-02        0.559096  ...   \n",
            "3  1.864905e-09  9.999897e-01    9.997150e-01        0.026577  ...   \n",
            "4  1.186832e-30  1.511544e-07    6.442329e-19        0.956502  ...   \n",
            "\n",
            "    Right_hyper  Right_Myopia     Right_age  N  D  G  C  A  H  M  \n",
            "0  2.096240e-10  5.021408e-19  5.854326e-08  0  0  0  1  0  0  0  \n",
            "1  7.124127e-05  6.208016e-20  8.317010e-04  1  0  0  0  0  0  0  \n",
            "2  3.397288e-05  7.831271e-22  1.857797e-03  0  1  0  0  0  0  0  \n",
            "3  1.654339e-14  1.517663e-11  9.999999e-01  0  1  0  0  0  0  0  \n",
            "4  1.224296e-08  8.968514e-26  6.348591e-01  0  1  0  0  0  0  0  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Batch from 0 to 5 processed and saved to predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "results = []\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\"):\n",
        "    age = row['Patient Age']\n",
        "    sex = row['Patient Sex']\n",
        "    left_fundus = os.path.join(dataset_dir, row['Left-Fundus'])\n",
        "    right_fundus = os.path.join(dataset_dir, row['Right-Fundus'])\n",
        "    correct_diagnosis = [row['N'], row['D'], row['G'], row['C'], row['A'], row['H'], row['M']]\n",
        "\n",
        "    # Perform prediction\n",
        "    prediction = load_and_predict(left_fundus, right_fundus)\n",
        "\n",
        "    if prediction:\n",
        "        cataract_prob, diabetic_prob, glaucoma_prob, hyper_prob, myopia_prob, age_prob = prediction\n",
        "\n",
        "        # Assertions for prediction format\n",
        "        assert isinstance(prediction, (list, tuple)), f\"Prediction should be a list/tuple, got {type(prediction)}\"\n",
        "        assert len(prediction) == 6, f\"Prediction should have 6 elements, got {len(prediction)}\"\n",
        "\n",
        "        # Assertions for individual probabilities\n",
        "        for i, prob in enumerate(prediction):\n",
        "            assert len(prob) == 2, f\"Each prediction entry should have left and right results, element {i} has {len(prob)}\"\n",
        "            assert all(isinstance(val, np.float32) for val in prob[0]), f\"Left results should be floats, got {prob[0]}\"\n",
        "            assert all(isinstance(val, np.float32) for val in prob[1]), f\"Right results should be floats, got {prob[1]}\"\n",
        "\n",
        "        # Left and Right eye results\n",
        "        left_sorted = [cataract_prob[0][0], diabetic_prob[0][0], glaucoma_prob[0][0],\n",
        "                       hyper_prob[0][0], myopia_prob[0][0], age_prob[0][0]]\n",
        "        right_sorted = [cataract_prob[1][0], diabetic_prob[1][0], glaucoma_prob[1][0],\n",
        "                        hyper_prob[1][0], myopia_prob[1][0], age_prob[1][0]]\n",
        "\n",
        "        # Assertions for left and right sorted lists\n",
        "        assert len(left_sorted) == 6, f\"Left results should contain 6 elements, got {len(left_sorted)}\"\n",
        "        assert len(right_sorted) == 6, f\"Right results should contain 6 elements, got {len(right_sorted)}\"\n",
        "        assert all(isinstance(val, np.float32) for val in left_sorted), \"Left results should only contain float values\"\n",
        "        assert all(isinstance(val, np.float32) for val in right_sorted), \"Right results should only contain float values\"\n",
        "\n",
        "        # Append results\n",
        "        results.append([age, sex] + left_sorted + right_sorted + correct_diagnosis)\n",
        "\n",
        "        # Assertions for final results structure\n",
        "        assert len(results[-1]) == 2 + 6 + 6 + len(correct_diagnosis), (\n",
        "            f\"Each result entry should have {2 + 6 + 6 + len(correct_diagnosis)} elements, \"\n",
        "            f\"got {len(results[-1])}\"\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv2sZAKw2EJF",
        "outputId": "4fccf66d-8338-4a9b-a679-dc9f8b48aaef"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing rows: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cach_df.shape (6392, 19)\n",
        "\n"
      ],
      "metadata": {
        "id": "NkTQ_Adw55n5",
        "outputId": "81de7a10-e29b-46a0-b3b9-22d65f9494fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6392, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assertions for the overall results list\n",
        "assert len(results) == df.shape[0], f\"Results should have {df.shape[0]} entries, got {len(results)}\"\n",
        "columns = ['Age', 'Sex', 'Left_cataract', 'Left_diabetic', 'Left_glaucoma', 'Left_hyper', 'Left_Myopia', 'Left_age',\n",
        "           'Right_cataract', 'Right_diabetic', 'Right_glaucoma', 'Right_hyper', 'Right_Myopia', 'Right_age',\n",
        "           'N', 'D', 'G', 'C', 'A', 'H', 'M']\n",
        "results_df = pd.DataFrame(results, columns=columns)\n",
        "\n",
        "\n",
        "\n",
        "# Save to CSV\n",
        "#results_df.to_csv(\"predictions.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "M3KlFGh05n2P",
        "outputId": "1ec2798e-3469-4e87-d3ae-b5073812e255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-fb93377f6ae0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assertions for the overall results list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Results should have {df.shape[0]} entries, got {len(results)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m columns = ['Age', 'Sex', 'Left_cataract', 'Left_diabetic', 'Left_glaucoma', 'Left_hyper', 'Left_Myopia', 'Left_age',\n\u001b[1;32m      4\u001b[0m            \u001b[0;34m'Right_cataract'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Right_diabetic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Right_glaucoma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Right_hyper'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Right_Myopia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Right_age'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            'N', 'D', 'G', 'C', 'A', 'H', 'M']\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display DataFrame\n",
        "results_df.head()"
      ],
      "metadata": {
        "id": "x84DRBDd9hP7",
        "outputId": "8da82e48-e5aa-492f-fdf7-b2c33206d822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-438812859770>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Display DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build DataFrame\n",
        "columns = ['Age', 'Sex', 'Left_cataract', 'Left_diabetic', 'Left_glaucoma', 'Left_hyper', 'Left_Myopia', 'Left_age',\n",
        "           'Right_cataract', 'Right_diabetic', 'Right_glaucoma', 'Right_hyper', 'Right_Myopia', 'Right_age',\n",
        "           'N', 'D', 'G', 'C', 'A', 'H', 'M']\n",
        "results_df = pd.DataFrame(results, columns=columns)\n",
        "\n",
        "# Display DataFrame\n",
        "results_df.head()\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv(\"predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "32bAHbSUg-4B"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.head()"
      ],
      "metadata": {
        "id": "G5F2WA1ci9FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Step 2: Reading images, applying preprocessing, and using Diagnoser\n",
        "dataset_dir = \"/content/ODIR-5K/ODIR-5K/Training Images\"\n",
        "image_size = 224\n",
        "\n",
        "def load_and_predict(image_list):\n",
        "    #Loads, preprocesses, and predicts using Diagnoser for a list of images\n",
        "    diagnoser = Diagnoser()\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/cataract_model_wiht_filter.keras\", CataractPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/diabetic_model_wiht_filter.keras\", DiabetesPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/glaucoma_model_wiht_filter.keras\", GlaucomaPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/hyper_model_wiht_filter.keras\", HypertensionPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/Myopia_model_2.h5\", PathologicalMyopiaPreprocessing()))\n",
        "    diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/age_model_wiht_filter.keras\", AgeIssuesPreprocessing()))\n",
        "\n",
        "    predictions = []\n",
        "    for img_file in tqdm(image_list, desc=\"Predicting images\"):\n",
        "        image_path = os.path.join(dataset_dir, img_file)\n",
        "        try:\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "            if image is None:\n",
        "                print(f\"Warning: Could not read image at {image_path}\")\n",
        "                predictions.append(None) # or some default value\n",
        "                continue\n",
        "            image = cv2.resize(image, (image_size, image_size))\n",
        "            prediction = diagnoser.predict(image, image) # Assuming both eyes are\n",
        "            prediction = diagnoser.predict(image, image) # Assuming both eyes are the same for simplicity\n",
        "            predictions.append(prediction)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_path}: {e}\")\n",
        "            predictions.append(None) # or some default value\n",
        "    return predictions\n",
        "\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "v0luAnlY7vt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09cMWOJR8nu2",
        "outputId": "3199cf24-6c48-4f16-9795-aac553e13ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Predicting Myopia images\n",
        "myopia_predictions = load_and_predict(myopia[:3])\n",
        "\n",
        "# Example: Display first prediction\n",
        "if myopia_predictions and myopia_predictions[0]:\n",
        "    print(\"Example Myopia Prediction:\", myopia_predictions[0])\n",
        "else:\n",
        "    print(\"No predictions were made.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-bQzBleU8NxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBJl1wcYYmeR",
        "outputId": "c60d00fe-e12e-4b7f-c574-f1d6d06ab8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.5612805e-14"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = EyesModel(\"/content/drive/MyDrive/F5_project/cataract_model_wiht_filter.keras\", CataractPreprocessing())"
      ],
      "metadata": {
        "id": "wFsZi1o1-yHo"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glu_model = EyesModel(\"/content/drive/MyDrive/F5_project/glaucoma_model_wiht_filter.keras\", GlaucomaPreprocessing())"
      ],
      "metadata": {
        "id": "tDQoY5GX_80N"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age, sex, left_fundus, right_fundus, correct_diagnosis = 0,0, 0,0, 0\n",
        "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\"):\n",
        "    age = row['Patient Age']\n",
        "    sex = row['Patient Sex']\n",
        "    left_fundus = os.path.join(dataset_dir, row['Left-Fundus'])\n",
        "    right_fundus = os.path.join(dataset_dir, row['Right-Fundus'])\n",
        "    correct_diagnosis = [row['N'], row['D'], row['G'], row['C'], row['A'], row['H'], row['M']]"
      ],
      "metadata": {
        "id": "51a0KvjZ_KdP",
        "outputId": "f7b10512-59ae-418c-cbaf-eabc099944c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing rows: 100%|██████████| 1/1 [00:00<00:00, 258.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "left_image = cv2.imread(left_fundus, cv2.IMREAD_COLOR)\n",
        "right_image = cv2.imread(right_fundus, cv2.IMREAD_COLOR)\n",
        "\n",
        "left_image = cv2.resize(left_image, (image_size, image_size))\n",
        "right_image = cv2.resize(right_image, (image_size, image_size))\n"
      ],
      "metadata": {
        "id": "HT4W2cnh_kfW"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_res = cat_model.diagnose(left_image, right_image)"
      ],
      "metadata": {
        "id": "Y6IBkjZo-30H",
        "outputId": "d78415d6-9a59-4127-f4a1-7146661894b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_res[0][0]"
      ],
      "metadata": {
        "id": "iQR1butE_yLj",
        "outputId": "faea4d69-7a74-415e-d921-689d2aa2a175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glu_res = glu_model.diagnose(left_image, right_image)"
      ],
      "metadata": {
        "id": "vwY685J8ABIr",
        "outputId": "86152155-2d20-4f1c-f87d-b698482c7390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glu_res[0][0]"
      ],
      "metadata": {
        "id": "MjAP2uXPAE1w",
        "outputId": "fbb8b5c1-760d-4bfe-eeda-2f4b05ad5863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17529409"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Example: Predicting Cataract images\n",
        "cataract_predictions = load_and_predict(cataract)\n",
        "\n",
        "# Example: Display first prediction\n",
        "if cataract_predictions and cataract_predictions[0]:\n",
        "    print(\"Example Cataract Prediction:\", cataract_predictions[0])\n",
        "else:\n",
        "    print(\"No predictions were made.\")\n",
        "\n",
        "# Example: Predicting Diabetes images\n",
        "diabetes_predictions = load_and_predict(diab)\n",
        "\n",
        "# Example: Display first prediction\n",
        "if diabetes_predictions and diabetes_predictions[0]:\n",
        "    print(\"Example Diabetes Prediction:\", diabetes_predictions[0])\n",
        "else:\n",
        "    print(\"No predictions were made.\")\n",
        "\n",
        "# Example: Predicting Glaucoma images\n",
        "glaucoma_predictions = load_and_predict(glaucoma)\n",
        "\n",
        "# Example: Display first prediction\n",
        "if glaucoma_predictions and glaucoma_predictions[0]:\n",
        "    print(\"Example Glaucoma Prediction:\", glaucoma_predictions[0])\n",
        "else:\n",
        "    print(\"No predictions were made.\")\n",
        "\n",
        "# Example: Predicting Hypertension images\n",
        "hypertension_predictions = load_and_predict(hyper)\n",
        "\n",
        "# Example: Display first prediction\n",
        "if hypertension_predictions and hypertension_predictions[0]:\n",
        "    print(\"Example Hypertension Prediction:\", hypertension_predictions[0])\n",
        "else:\n",
        "    print(\"No predictions were made.\")\n",
        "\n",
        "# Example: Predicting Age issues images\n",
        "age_predictions = load_and_predict(age)\n",
        "\n",
        "# Example: Display first prediction\n",
        "if age_predictions and age_predictions[0]:\n",
        "    print(\"Example Age issues Prediction:\", age_predictions[0])\n",
        "else:\n",
        "    print(\"No predictions were made.\")\n",
        "\n",
        "# Example: Predicting other images\n",
        "other_predictions = load_and_predict(other)\n",
        "\n",
        "# Example: Display first prediction\n",
        "if other_predictions and other_predictions[0]:\n",
        "    print(\"Example Other issues Prediction:\", other_predictions[0])\n",
        "else:\n",
        "    print(\"No predictions were made.\")\n",
        "\n",
        "# Example: Predicting Normal images\n",
        "normal_predictions = load_and_predict(normal)\n",
        "\n",
        "# Example: Display first prediction\n",
        "if normal_predictions and normal_predictions[0]:\n",
        "    print(\"Example Normal issues Prediction:\", normal_predictions[0])\n",
        "else:\n",
        "    print(\"No predictions were made.\")"
      ],
      "metadata": {
        "id": "E3Tn-zD68KRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}