{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import threading\n"
      ],
      "metadata": {
        "id": "OV3FwxsZ-geu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected Singleton Metaclass\n",
        "class Singleton(type):\n",
        "    _instances = {}\n",
        "    def __call__(cls, *args, **kwargs):\n",
        "        if cls not in cls._instances:\n",
        "            cls._instances[cls] = super().__call__(*args, **kwargs)  # Corrected super() call\n",
        "        return cls._instances[cls]\n",
        "\n",
        "# Model Loader Factory (same as before)\n",
        "class ModelLoaderFactory:\n",
        "    loaders = {\n",
        "\n",
        "               \"keras\" : lambda path: tf.keras.models.load_model(path),\n",
        "               \"h5\": lambda path: tf.keras.models.load_model(path),\n",
        "               \"pb\": lambda path: tf.saved_model.load(path),\n",
        "               \"pt\": lambda path: torch.jit.load(path)}\n",
        "\n",
        "    @staticmethod\n",
        "    def get_loader(extension):\n",
        "        loader = ModelLoaderFactory.loaders.get(extension.lower())\n",
        "        if loader is None:\n",
        "            raise ValueError(f\"Unsupported model format: {extension}\")\n",
        "        return loader\n",
        "\n"
      ],
      "metadata": {
        "id": "1cC64gFl6mvH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Strategies (Singleton) (same as before)\n",
        "class PreprocessingStrategy(metaclass=Singleton):\n",
        "    def apply(self, image):\n",
        "        raise NotImplementedError(\"Subclasses must implement apply method.\")\n",
        "\n",
        "class CataractPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        return cv2.convertScaleAbs(image, alpha=1.0, beta=50)\n",
        "\n",
        "class DiabetesPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        green_channel = image[:, :, 1]\n",
        "        red_free_image = cv2.merge([green_channel, green_channel, green_channel])\n",
        "        return cv2.convertScaleAbs(red_free_image, alpha=1.5, beta=50)\n",
        "\n",
        "class GlaucomaPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = image / 255.0\n",
        "        return image.astype(np.float32)\n",
        "\n",
        "class HypertensionPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        green_channel = image[:, :, 1]\n",
        "        red_free_image = cv2.equalizeHist(green_channel)\n",
        "        edges = cv2.Canny(red_free_image, 50, 150)\n",
        "        blurred = cv2.GaussianBlur(red_free_image, (5, 5), 0)\n",
        "        return np.stack([red_free_image, edges, blurred], axis=-1)\n",
        "\n",
        "class PathologicalMyopiaPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        return cv2.resize(image, (224, 224))\n",
        "\n",
        "class AgeIssuesPreprocessing(PreprocessingStrategy):\n",
        "    def apply(self, image):\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "        enhanced_image = clahe.apply(gray_image)\n",
        "        image_faf = cv2.cvtColor(enhanced_image, cv2.COLOR_GRAY2BGR)\n",
        "        edges = cv2.Canny(image, 100, 200)\n",
        "        return cv2.addWeighted(image, 0.8, cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 0.2, 0)\n"
      ],
      "metadata": {
        "id": "QAyIkvPT6uP-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eyes Model (same as before)\n",
        "class EyesModel:\n",
        "    _model_cache = {}\n",
        "    _cache_lock = threading.Lock()\n",
        "\n",
        "\n",
        "    def __init__(self, model_path, strategy):\n",
        "        self.model_path = model_path\n",
        "        self.strategy = strategy\n",
        "        self.model = self._load_model()\n",
        "\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        # Two models are considered equal if they share the same path and strategy\n",
        "        return isinstance(other, EyesModel) and \\\n",
        "               self.model_path == other.model_path and \\\n",
        "               type(self.strategy) == type(other.strategy)\n",
        "\n",
        "    def __hash__(self):\n",
        "        # Hash based on model path and strategy type\n",
        "        return hash((self.model_path, type(self.strategy)))\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"EyesModel(model_path={self.model_path}, strategy={type(self.strategy)})\"\n",
        "\n",
        "    def _load_model(self):\n",
        "        with EyesModel._cache_lock:\n",
        "            if self.model_path not in EyesModel._model_cache:\n",
        "                extension = self.model_path.split('.')[-1]\n",
        "                loader = ModelLoaderFactory.get_loader(extension)\n",
        "                if loader:\n",
        "                    EyesModel._model_cache[self.model_path] = loader(self.model_path)\n",
        "            return EyesModel._model_cache[self.model_path]\n",
        "\n",
        "    def diagnose(self, left_image, right_image):\n",
        "        left_processed = self.strategy.apply(left_image)\n",
        "        right_processed = self.strategy.apply(right_image)\n",
        "        left_result = self.model.predict(np.expand_dims(left_processed, axis=0))[0]\n",
        "        right_result = self.model.predict(np.expand_dims(right_processed, axis=0))[0]\n",
        "        return left_result, right_result\n"
      ],
      "metadata": {
        "id": "Ojo9L35wnXyf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "class Diagnoser:\n",
        "    def __init__(self):\n",
        "        # Use a list to store models and ensure uniqueness\n",
        "        self.models = []\n",
        "\n",
        "    def add_model(self, model):\n",
        "        \"\"\"\n",
        "        Add a model to the Diagnoser, ensuring uniqueness based on __hash__ and __eq__.\n",
        "        \"\"\"\n",
        "        if model not in self.models:\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict(self, left_image, right_image, parallel=False):\n",
        "        \"\"\"\n",
        "        Generate predictions using all models.\n",
        "\n",
        "        Args:\n",
        "        - left_image: Image for the left eye.\n",
        "        - right_image: Image for the right eye.\n",
        "        - parallel (bool): Whether to execute predictions in parallel.\n",
        "\n",
        "        Returns:\n",
        "        - results (list): Predictions from all models in the correct order.\n",
        "        \"\"\"\n",
        "        if parallel:\n",
        "            # Map each model to its index to maintain order\n",
        "            model_to_index = {model: idx for idx, model in enumerate(self.models)}\n",
        "\n",
        "            # Function to process a model and preserve index\n",
        "            def process_model(model):\n",
        "                return model_to_index[model], model.diagnose(left_image, right_image)\n",
        "\n",
        "            # Initialize a list to store results in the correct order\n",
        "            results = [None] * len(self.models)\n",
        "\n",
        "            # Execute predictions in parallel with ThreadPoolExecutor\n",
        "            with ThreadPoolExecutor() as executor:\n",
        "                for index, result in executor.map(process_model, self.models):\n",
        "                    results[index] = result  # Store results at respective indices\n",
        "\n",
        "        else:\n",
        "            # Serial execution ensures order naturally\n",
        "            results = [model.diagnose(left_image, right_image) for model in self.models]\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "8u_MCEZk7Ux4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming Diagnoser, EyesModel, and Preprocessing strategies are defined as in the previous response\n",
        "\n",
        "# Step 1: Loading the dataset and organizing image paths\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"magdhndi\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"9b6c8953fb75d807a407f863ae22edc6\"\n",
        "\n",
        "!kaggle datasets download andrewmvd/ocular-disease-recognition-odir5k\n",
        "!unzip ocular-disease-recognition-odir5k\n"
      ],
      "metadata": {
        "id": "GtdP73bS7ZPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/full_df.csv\")\n",
        "\n",
        "cach_df = df\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GokkcSp87gJW",
        "outputId": "92ac83df-173d-4753-cd4e-f852f4cf0696"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
              "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
              "1   1           57        Male  1_left.jpg  1_right.jpg   \n",
              "2   2           42        Male  2_left.jpg  2_right.jpg   \n",
              "3   4           53        Male  4_left.jpg  4_right.jpg   \n",
              "4   5           50      Female  5_left.jpg  5_right.jpg   \n",
              "\n",
              "                            Left-Diagnostic Keywords  \\\n",
              "0                                           cataract   \n",
              "1                                      normal fundus   \n",
              "2  laser spot，moderate non proliferative retinopathy   \n",
              "3                        macular epiretinal membrane   \n",
              "4             moderate non proliferative retinopathy   \n",
              "\n",
              "                Right-Diagnostic Keywords  N  D  G  C  A  H  M  O  \\\n",
              "0                           normal fundus  0  0  0  1  0  0  0  0   \n",
              "1                           normal fundus  1  0  0  0  0  0  0  0   \n",
              "2  moderate non proliferative retinopathy  0  1  0  0  0  0  0  1   \n",
              "3       mild nonproliferative retinopathy  0  1  0  0  0  0  0  1   \n",
              "4  moderate non proliferative retinopathy  0  1  0  0  0  0  0  0   \n",
              "\n",
              "                                            filepath labels  \\\n",
              "0  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
              "1  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
              "2  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
              "3  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
              "4  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
              "\n",
              "                     target     filename  \n",
              "0  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg  \n",
              "1  [1, 0, 0, 0, 0, 0, 0, 0]  1_right.jpg  \n",
              "2  [0, 1, 0, 0, 0, 0, 0, 0]  2_right.jpg  \n",
              "3  [0, 1, 0, 0, 0, 0, 0, 0]  4_right.jpg  \n",
              "4  [0, 1, 0, 0, 0, 0, 0, 0]  5_right.jpg  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d52d3849-6a2c-4a3c-939d-338d0b406684\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Sex</th>\n",
              "      <th>Left-Fundus</th>\n",
              "      <th>Right-Fundus</th>\n",
              "      <th>Left-Diagnostic Keywords</th>\n",
              "      <th>Right-Diagnostic Keywords</th>\n",
              "      <th>N</th>\n",
              "      <th>D</th>\n",
              "      <th>G</th>\n",
              "      <th>C</th>\n",
              "      <th>A</th>\n",
              "      <th>H</th>\n",
              "      <th>M</th>\n",
              "      <th>O</th>\n",
              "      <th>filepath</th>\n",
              "      <th>labels</th>\n",
              "      <th>target</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>Female</td>\n",
              "      <td>0_left.jpg</td>\n",
              "      <td>0_right.jpg</td>\n",
              "      <td>cataract</td>\n",
              "      <td>normal fundus</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['N']</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>0_right.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>Male</td>\n",
              "      <td>1_left.jpg</td>\n",
              "      <td>1_right.jpg</td>\n",
              "      <td>normal fundus</td>\n",
              "      <td>normal fundus</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['N']</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>1_right.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>Male</td>\n",
              "      <td>2_left.jpg</td>\n",
              "      <td>2_right.jpg</td>\n",
              "      <td>laser spot，moderate non proliferative retinopathy</td>\n",
              "      <td>moderate non proliferative retinopathy</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['D']</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>2_right.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>Male</td>\n",
              "      <td>4_left.jpg</td>\n",
              "      <td>4_right.jpg</td>\n",
              "      <td>macular epiretinal membrane</td>\n",
              "      <td>mild nonproliferative retinopathy</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['D']</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>4_right.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>Female</td>\n",
              "      <td>5_left.jpg</td>\n",
              "      <td>5_right.jpg</td>\n",
              "      <td>moderate non proliferative retinopathy</td>\n",
              "      <td>moderate non proliferative retinopathy</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
              "      <td>['D']</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>5_right.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d52d3849-6a2c-4a3c-939d-338d0b406684')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d52d3849-6a2c-4a3c-939d-338d0b406684 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d52d3849-6a2c-4a3c-939d-338d0b406684');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-062b00f7-33c3-4b33-9d96-77d1ce8a8873\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-062b00f7-33c3-4b33-9d96-77d1ce8a8873')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-062b00f7-33c3-4b33-9d96-77d1ce8a8873 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6392,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1417,\n        \"min\": 0,\n        \"max\": 4784,\n        \"num_unique_values\": 3358,\n        \"samples\": [\n          1419,\n          2470,\n          1975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 1,\n        \"max\": 91,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          50,\n          24,\n          58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Left-Fundus\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3358,\n        \"samples\": [\n          \"1419_left.jpg\",\n          \"2470_left.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Right-Fundus\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3358,\n        \"samples\": [\n          \"1419_right.jpg\",\n          \"2470_right.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Left-Diagnostic Keywords\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 196,\n        \"samples\": [\n          \"glaucoma\\uff0cmyopia retinopathy\",\n          \"suspected glaucoma\\uff0csuspicious diabetic retinopathy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Right-Diagnostic Keywords\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 205,\n        \"samples\": [\n          \"dry age-related macular degeneration\\uff0cglaucoma\",\n          \"drusen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"G\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"O\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filepath\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6392,\n        \"samples\": [\n          \"../input/ocular-disease-recognition-odir5k/ODIR-5K/Training Images/3969_right.jpg\",\n          \"../input/ocular-disease-recognition-odir5k/ODIR-5K/Training Images/2391_left.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"['D']\",\n          \"['C']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"[0, 1, 0, 0, 0, 0, 0, 0]\",\n          \"[0, 0, 0, 1, 0, 0, 0, 0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6392,\n        \"samples\": [\n          \"3969_right.jpg\",\n          \"2391_left.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bECe8LTmfO_x",
        "outputId": "1f5d483d-eaab-4dff-a540-413ce81c3653"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.head(1)\n",
        "dataset_dir = \"/content/ODIR-5K/ODIR-5K/Training Images\"\n",
        "image_size = 224\n",
        "\n",
        "diagnoser = Diagnoser()\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/cataract_model_wiht_filter.keras\", CataractPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/diabetic_model_wiht_filter.keras\", DiabetesPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/glaucoma_model_wiht_filter.keras\", GlaucomaPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/hyper_model_wiht_filter.keras\", HypertensionPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/Myopia_model_2.h5\", PathologicalMyopiaPreprocessing()))\n",
        "diagnoser.add_model(EyesModel(\"/content/drive/MyDrive/F5_project/age_model_wiht_filter.keras\", AgeIssuesPreprocessing()))\n"
      ],
      "metadata": {
        "id": "e6U5-Xt7fJW-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in diagnoser.models:\n",
        "    print(type(model.strategy))  # Prints the class of each strategy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr7snNiRrfyt",
        "outputId": "09c6fecf-e47b-4052-d42b-494d5327651c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.CataractPreprocessing'>\n",
            "<class '__main__.DiabetesPreprocessing'>\n",
            "<class '__main__.GlaucomaPreprocessing'>\n",
            "<class '__main__.HypertensionPreprocessing'>\n",
            "<class '__main__.PathologicalMyopiaPreprocessing'>\n",
            "<class '__main__.AgeIssuesPreprocessing'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_predict(left_image_path, right_image_path):\n",
        "    \"\"\"Loads, preprocesses, and predicts using Diagnoser for a pair of images.\"\"\"\n",
        "    try:\n",
        "        left_image = cv2.imread(left_image_path, cv2.IMREAD_COLOR)\n",
        "        right_image = cv2.imread(right_image_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if left_image is None or right_image is None:\n",
        "            print(f\"Warning: Could not read one or both images.\")\n",
        "            return None\n",
        "\n",
        "        left_image = cv2.resize(left_image, (image_size, image_size))\n",
        "        right_image = cv2.resize(right_image, (image_size, image_size))\n",
        "\n",
        "        prediction = diagnoser.predict(left_image, right_image, parallel=True)  # Parallel execution with guaranteed order\n",
        "        return prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing images: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "_wAKkyZEghpX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def process_in_batches(df, start_row, batch_size, dataset_dir, output_file=\"predictions.csv\"):\n",
        "    \"\"\"\n",
        "    Processes rows in the DataFrame in batches and saves predictions to a CSV file.\n",
        "\n",
        "    Args:\n",
        "    - df (pd.DataFrame): Input DataFrame with records to process.\n",
        "    - start_row (int): Starting row index.\n",
        "    - batch_size (int): Number of rows to process in each batch.\n",
        "    - dataset_dir (str): Directory containing the images.\n",
        "    - output_file (str): Path to the output CSV file.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # Ensure start_row and batch_size are valid\n",
        "    assert start_row >= 0, \"Start row must be non-negative\"\n",
        "    assert batch_size > 0, \"Batch size must be a positive integer\"\n",
        "\n",
        "    # Slice the DataFrame for the given batch\n",
        "    end_row = min(start_row + batch_size, len(df))\n",
        "    batch_df = df.iloc[start_row:end_row]\n",
        "\n",
        "    # Initialize results list\n",
        "    results = []\n",
        "\n",
        "    # Process each row in the batch\n",
        "    for index, row in tqdm(batch_df.iterrows(), total=batch_df.shape[0], desc=f\"Processing rows {start_row} to {end_row}\"):\n",
        "        age = row['Patient Age']\n",
        "        sex = row['Patient Sex']\n",
        "        left_fundus = os.path.join(dataset_dir, row['Left-Fundus'])\n",
        "        right_fundus = os.path.join(dataset_dir, row['Right-Fundus'])\n",
        "        correct_diagnosis = [row['N'], row['D'], row['G'], row['C'], row['A'], row['H'], row['M']]\n",
        "\n",
        "        # Perform prediction\n",
        "        prediction = load_and_predict(left_fundus, right_fundus)\n",
        "\n",
        "        if prediction:\n",
        "            cataract_prob, diabetic_prob, glaucoma_prob, hyper_prob, myopia_prob, age_prob = prediction\n",
        "\n",
        "            # Left and right eye results\n",
        "            left_sorted = [cataract_prob[0][0], diabetic_prob[0][0], glaucoma_prob[0][0],\n",
        "                           hyper_prob[0][0], myopia_prob[0][0], age_prob[0][0]]\n",
        "            right_sorted = [cataract_prob[1][0], diabetic_prob[1][0], glaucoma_prob[1][0],\n",
        "                            hyper_prob[1][0], myopia_prob[1][0], age_prob[1][0]]\n",
        "\n",
        "            # Append results\n",
        "            results.append([age, sex] + left_sorted + right_sorted + correct_diagnosis)\n",
        "\n",
        "\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "0wFhx68q8InO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "# Assuming `df` is already defined and loaded\n",
        "results = process_in_batches(cach_df, start_row=0, batch_size=5, dataset_dir=\"/content/ODIR-5K/ODIR-5K/Training Images\", output_file=\"predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XtR4FJHJtaN",
        "outputId": "388140e2-0787-4119-a455-e1d13ace3b14"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:  20%|██        | 1/5 [00:07<00:29,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:  40%|████      | 2/5 [00:13<00:20,  6.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:  60%|██████    | 3/5 [00:22<00:15,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows 0 to 5:  80%|████████  | 4/5 [00:28<00:07,  7.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing rows 0 to 5: 100%|██████████| 5/5 [00:38<00:00,  7.66s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file=\"predictions.csv\"\n",
        "start_row=0\n",
        "end_row = 5\n",
        "batch_df = cach_df.iloc[start_row:end_row]\n",
        "# Assertions for the batch results\n",
        "assert len(results) == len(batch_df), f\"Results length mismatch: expected {len(batch_df)}, got {len(results)}\"\n",
        "\n",
        "# Define column names\n",
        "columns = ['Age', 'Sex', 'Left_cataract', 'Left_diabetic', 'Left_glaucoma', 'Left_hyper', 'Left_Myopia', 'Left_age',\n",
        "            'Right_cataract', 'Right_diabetic', 'Right_glaucoma', 'Right_hyper', 'Right_Myopia', 'Right_age',\n",
        "            'N', 'D', 'G', 'C', 'A', 'H', 'M']\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results, columns=columns)\n",
        "\n",
        "# Display a preview of the results\n",
        "print(results_df.head())\n",
        "\n",
        "# Save results to a CSV file\n",
        "if os.path.exists(output_file):\n",
        "    # Append without overwriting the file\n",
        "    results_df.to_csv(output_file, mode='a', header=False, index=False)\n",
        "else:\n",
        "    # Create a new file\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Batch from {start_row} to {end_row} processed and saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmhvfxV7JoJj",
        "outputId": "39a4fb2c-7bc3-4f8c-f3fd-8d240a1b75e6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Age     Sex  Left_cataract  Left_diabetic  Left_glaucoma    Left_hyper  \\\n",
            "0   69  Female   1.000000e+00   2.546632e-06       0.175294  6.784076e-10   \n",
            "1   57    Male   3.026999e-09   1.389067e-01       0.221712  1.051806e-07   \n",
            "2   42    Male   9.973556e-01   9.979500e-01       0.198193  6.392049e-11   \n",
            "3   53    Male   8.908896e-01   2.037923e-07       0.343581  2.397901e-11   \n",
            "4   50  Female   6.744714e-17   2.790738e-05       0.192183  2.162522e-10   \n",
            "\n",
            "    Left_Myopia      Left_age  Right_cataract  Right_diabetic  ...  \\\n",
            "0  4.678401e-17  3.261969e-02    6.574120e-02        0.000059  ...   \n",
            "1  3.471462e-22  3.751020e-03    4.485955e-12        0.003587  ...   \n",
            "2  1.102241e-08  9.995713e-01    1.676708e-02        0.559096  ...   \n",
            "3  1.864905e-09  9.999897e-01    9.997150e-01        0.026577  ...   \n",
            "4  1.186832e-30  1.511544e-07    6.442329e-19        0.956502  ...   \n",
            "\n",
            "    Right_hyper  Right_Myopia     Right_age  N  D  G  C  A  H  M  \n",
            "0  2.096240e-10  5.021408e-19  5.854326e-08  0  0  0  1  0  0  0  \n",
            "1  7.124127e-05  6.208016e-20  8.317010e-04  1  0  0  0  0  0  0  \n",
            "2  3.397288e-05  7.831271e-22  1.857797e-03  0  1  0  0  0  0  0  \n",
            "3  1.654339e-14  1.517663e-11  9.999999e-01  0  1  0  0  0  0  0  \n",
            "4  1.224296e-08  8.968514e-26  6.348591e-01  0  1  0  0  0  0  0  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Batch from 0 to 5 processed and saved to predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cach_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkTQ_Adw55n5",
        "outputId": "ccae147d-70d5-42a1-e3e1-c6b44369b750"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6392, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Just for Example"
      ],
      "metadata": {
        "id": "RDwRAzQYRgsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = EyesModel(\"/content/drive/MyDrive/F5_project/cataract_model_wiht_filter.keras\", CataractPreprocessing())"
      ],
      "metadata": {
        "id": "wFsZi1o1-yHo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glu_model = EyesModel(\"/content/drive/MyDrive/F5_project/glaucoma_model_wiht_filter.keras\", GlaucomaPreprocessing())"
      ],
      "metadata": {
        "id": "tDQoY5GX_80N"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age, sex, left_fundus, right_fundus, correct_diagnosis = 0,0, 0,0, 0\n",
        "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\"):\n",
        "    age = row['Patient Age']\n",
        "    sex = row['Patient Sex']\n",
        "    left_fundus = os.path.join(dataset_dir, row['Left-Fundus'])\n",
        "    right_fundus = os.path.join(dataset_dir, row['Right-Fundus'])\n",
        "    correct_diagnosis = [row['N'], row['D'], row['G'], row['C'], row['A'], row['H'], row['M']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51a0KvjZ_KdP",
        "outputId": "9c022e85-5e22-4c1b-992f-f4daeb195b34"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing rows: 100%|██████████| 1/1 [00:00<00:00, 804.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "left_image = cv2.imread(left_fundus, cv2.IMREAD_COLOR)\n",
        "right_image = cv2.imread(right_fundus, cv2.IMREAD_COLOR)\n",
        "\n",
        "left_image = cv2.resize(left_image, (image_size, image_size))\n",
        "right_image = cv2.resize(right_image, (image_size, image_size))\n"
      ],
      "metadata": {
        "id": "HT4W2cnh_kfW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_res = cat_model.diagnose(left_image, right_image)\n",
        "glu_res = glu_model.diagnose(left_image, right_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6IBkjZo-30H",
        "outputId": "8206f516-da10-4b51-bf31-8033f6dfc319"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"for Cat:\")\n",
        "print(\"Left_probability: \", cat_res[0][0], \", \", \"Right_probability: \", cat_res[1][0])\n",
        "print(\"\\n for Glu:\")\n",
        "print(\"Left_probability: \", glu_res[0][0], \", \", \"Right_probability: \", glu_res[1][0])\n",
        "print(\"\\n\\nIt's work because the correct answer is Cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwY685J8ABIr",
        "outputId": "714433f3-dd8a-401e-d107-05538663732c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for Cat:\n",
            "Left_probability:  1.0 ,  Right_probability:  0.0657412\n",
            "\n",
            " for Glu:\n",
            "Left_probability:  0.17529409 ,  Right_probability:  0.1643432\n",
            "\n",
            "\n",
            "It's work because the correct answer is Cat\n"
          ]
        }
      ]
    }
  ]
}